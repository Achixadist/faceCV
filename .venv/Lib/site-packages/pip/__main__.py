import cv2
import numpy as np
import time
import os
import requests
import json


class Insta360LinkController:
    """Controller class for Insta360 Link camera PTZ features using the camera's API"""

    def __init__(self, camera_id=0, ip_address="127.0.0.1", port=8090):
        self.camera_id = camera_id
        self.ip_address = ip_address
        self.port = port
        self.api_base_url = f"http://{ip_address}:{port}/api"
        self.ptz_supported = self._check_ptz_support()
        print(f"Insta360 Link Controller initialized. PTZ support: {self.ptz_supported}")

    def _check_ptz_support(self):
        """Check if PTZ is supported on this camera by querying its capabilities"""
        try:
            # Try to get camera capabilities via API
            response = requests.get(f"{self.api_base_url}/capabilities", timeout=2)
            if response.status_code == 200:
                capabilities = response.json()
                if "ptz" in capabilities and capabilities["ptz"] == True:
                    print("PTZ capabilities confirmed via API")
                    return True

            # If we can't confirm via API, try a test zoom command
            test_result = self._send_command("zoom", {"factor": 1.0})
            if test_result:
                print("PTZ support confirmed via test command")
                return True

            return False
        except Exception as e:
            print(f"PTZ support check failed: {e}")
            print("Assuming PTZ is not supported. Running in preview-only mode.")
            return False

    def _send_command(self, command_type, params):
        """Send a command to the camera API"""
        try:
            # Construct the command payload
            payload = {
                "command": command_type,
                "params": params
            }

            # Send the command to the camera API
            response = requests.post(
                f"{self.api_base_url}/control",
                json=payload,
                timeout=1  # Short timeout to prevent blocking
            )

            # Check if the command was successful
            if response.status_code == 200:
                result = response.json()
                if "status" in result and result["status"] == "success":
                    return True
                else:
                    print(f"Command {command_type} failed: {result.get('message', 'Unknown error')}")
            else:
                print(f"API request failed with status code: {response.status_code}")

            return False
        except requests.exceptions.RequestException as e:
            print(f"Error sending {command_type} command: {e}")
            return False

    def zoom(self, zoom_factor):
        """Set camera zoom level"""
        if not self.ptz_supported:
            print("Warning: PTZ not supported, zoom command ignored")
            return False

        try:
            # Ensure zoom_factor is within valid range
            zoom_factor = max(1.0, min(4.0, zoom_factor))

            # Send zoom command to camera
            result = self._send_command("zoom", {"factor": zoom_factor})
            if result:
                print(f"Zoom set to {zoom_factor:.2f}x")
            return result
        except Exception as e:
            print(f"Zoom command failed: {e}")
            return False

    def micro_pan_tilt(self, pan, tilt):
        """Apply small pan and tilt adjustments

        Args:
            pan: Pan value between -1.0 and 1.0 (negative is left, positive is right)
            tilt: Tilt value between -1.0 and 1.0 (negative is down, positive is up)
        """
        if not self.ptz_supported:
            return False

        try:
            # Ensure pan/tilt values are within valid range
            pan = max(-1.0, min(1.0, pan))
            tilt = max(-1.0, min(1.0, tilt))

            # Convert relative pan/tilt to absolute position adjustments
            # For the Insta360 Link, we need to use relative movement values
            params = {
                "pan_speed": pan,
                "tilt_speed": tilt,
                "duration": 100  # Duration in ms
            }

            result = self._send_command("pantilt", params)
            if result:
                print(f"Pan: {pan:.2f}, Tilt: {tilt:.2f}")
            return result
        except Exception as e:
            print(f"Pan/tilt command failed: {e}")
            return False

    def reset_position(self):
        """Reset camera to home position"""
        if not self.ptz_supported:
            return False

        try:
            result = self._send_command("preset", {"preset": "home"})
            if result:
                print("Camera position reset to home")
            return result
        except Exception as e:
            print(f"Reset position command failed: {e}")
            return False

    def get_current_zoom(self):
        """Get current zoom level from camera"""
        if not self.ptz_supported:
            return 1.0

        try:
            response = requests.get(f"{self.api_base_url}/status/zoom", timeout=1)
            if response.status_code == 200:
                status = response.json()
                if "zoom_factor" in status:
                    return float(status["zoom_factor"])

            # If we couldn't get the zoom level, return a default
            return 1.5
        except Exception as e:
            print(f"Get zoom command failed: {e}")
            return 1.0


def initialize_camera():
    """Try to initialize camera with fallback options"""
    for camera_id in range(3):  # Try camera indices 0, 1, 2
        print(f"Attempting to open camera {camera_id}...")
        cap = cv2.VideoCapture(camera_id)
        if cap.isOpened():
            print(f"Successfully opened camera {camera_id}")
            return cap, camera_id

    # If we get here, no camera could be opened
    print("ERROR: Could not open any camera. Please check camera connections.")
    return None, -1


def load_face_detector():
    """Load appropriate face detector based on available models"""
    # Initialize variables
    face_cascade = None
    net = None
    use_dnn_detector = False

    # First try to load Haar cascade
    try:
        cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        if os.path.exists(cascade_path):
            face_cascade = cv2.CascadeClassifier(cascade_path)
            if not face_cascade.empty():
                print("Haar cascade face detector loaded successfully")
            else:
                print("Error: Haar cascade file is invalid")
                face_cascade = None
        else:
            print(f"Error: Haar cascade file not found at {cascade_path}")
    except Exception as e:
        print(f"Error loading Haar cascade: {e}")

    # Try to load DNN-based detector if available
    try:
        # Check if the model files exist
        prototxt_path = "deploy.prototxt"
        model_path = "res10_300x300_ssd_iter_140000.caffemodel"

        if os.path.exists(prototxt_path) and os.path.exists(model_path):
            net = cv2.dnn.readNetFromCaffe(prototxt_path, model_path)
            use_dnn_detector = True
            print("DNN-based face detector loaded successfully")
        else:
            print(f"DNN model files not found. Looked for:")
            print(f"  - {os.path.abspath(prototxt_path)}")
            print(f"  - {os.path.abspath(model_path)}")
    except Exception as e:
        print(f"Error loading DNN detector: {e}")

    return face_cascade, net, use_dnn_detector


def main():
    print("Starting Insta360 Link Face Tracking...")

    # Load the pre-trained face detector
    face_cascade, net, use_dnn_detector = load_face_detector()

    if face_cascade is None and not use_dnn_detector:
        print("ERROR: No face detector could be loaded. Exiting.")
        return

    # Initialize the camera
    cap, camera_id = initialize_camera()
    if cap is None:
        return

    # Initialize the Insta360 Link camera controller
    link_controller = Insta360LinkController(
        camera_id=camera_id,
        ip_address="192.168.1.1",  # Replace with your camera's IP address
        port=80
    )

    # Get the original frame dimensions
    ret, frame = cap.read()
    if not ret:
        print("Error: Could not read from camera.")
        cap.release()
        return

    original_height, original_width = frame.shape[:2]
    center_x, center_y = original_width // 2, original_height // 2
    print(f"Camera resolution: {original_width}x{original_height}")

    # Initialize tracking variables
    zoom_factor = 1.5  # Start with 1.5x zoom as requested
    target_zoom = zoom_factor

    # Set initial zoom level immediately
    print("Setting initial zoom level to 1.5x")
    if link_controller.ptz_supported:
        link_controller.zoom(zoom_factor)
        # Wait briefly to ensure the command completes
        time.sleep(0.5)
        # Verify the zoom was applied
        current_zoom = link_controller.get_current_zoom()
        print(f"Current camera zoom level: {current_zoom}x")

    # PID control variables for tracking
    prev_offset_x = 0
    prev_offset_y = 0
    integral_x = 0
    integral_y = 0

    # PID constants
    kp = 0.5
    ki = 0.05
    kd = 0.15

    # Parameters for face tracking and zooming
    max_zoom = 3.0  # Max zoom level is 3x as requested
    min_zoom = 1.0  # Min zoom level is 1x as requested
    zoom_speed = 0.08  # Speed of zoom transitions

    # Movement threshold for face centering
    movement_threshold = 10

    # NEW: Variables for remembering initial face size
    initial_face_size = None
    initial_face_size_samples = []
    initial_samples_needed = 30  # Collect samples to get a stable initial size
    face_size_stabilization_counter = 0

    # Define zoom ranges and thresholds based on initial face size
    face_size_zoom_ratio = 1.0  # Will be calculated once initial face size is established

    # Timing variables
    last_ptz_command_time = time.time() - 1.0
    ptz_command_interval = 0.08
    last_zoom_command_time = time.time() - 1.0
    zoom_command_interval = 0.15

    # Face tracking history for smoother movement
    face_positions = []
    max_history = 8

    # Create a tracking window
    cv2.namedWindow("Insta360 Link Face Tracking")

    consecutive_tracking_frames = 0
    frames_without_face = 0
    last_successful_tracking_time = time.time()
    last_applied_zoom = zoom_factor

    # Debugging variables
    debug_mode = True
    command_sent = False

    # Zoom stability counters and flags
    zoom_command_success_counter = 0
    zoom_failure_counter = 0
    zoom_reset_needed = False
    last_zoom_verification_time = time.time()

    print("Face tracking system initialized and ready")
    print("Press 'q' to exit")

    # Main processing loop
    while True:
        # Capture frame
        ret, frame = cap.read()
        if not ret:
            print("Error: Could not read frame. Camera may be disconnected.")
            break

        current_time = time.time()
        command_sent = False

        # Initialize largest face variables
        largest_face_area = 0
        largest_face = None

        # Face detection using appropriate method
        if use_dnn_detector and net is not None:
            # DNN-based face detection (more robust)
            try:
                blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))
                net.setInput(blob)
                detections = net.forward()

                for i in range(detections.shape[2]):
                    confidence = detections[0, 0, i, 2]
                    if confidence > 0.5:  # Confidence threshold
                        box = detections[0, 0, i, 3:7] * np.array(
                            [original_width, original_height, original_width, original_height])
                        (x, y, x2, y2) = box.astype("int")
                        w = x2 - x
                        h = y2 - y

                        # Check for valid face dimensions
                        if w > 0 and h > 0:
                            face_area = w * h
                            if face_area > largest_face_area:
                                largest_face_area = face_area
                                largest_face = (x, y, w, h)
            except Exception as e:
                print(f"Error in DNN face detection: {e}")
                use_dnn_detector = False

        if not use_dnn_detector and face_cascade is not None:
            # Haar cascade detection
            try:
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                gray = cv2.equalizeHist(gray)

                faces = face_cascade.detectMultiScale(
                    gray,
                    scaleFactor=1.1,
                    minNeighbors=5,
                    minSize=(30, 30),
                    flags=cv2.CASCADE_SCALE_IMAGE
                )

                for (x, y, w, h) in faces:
                    face_area = w * h
                    if face_area > largest_face_area:
                        largest_face_area = face_area
                        largest_face = (x, y, w, h)
            except Exception as e:
                print(f"Error in Haar cascade face detection: {e}")

        # Track and zoom based on face
        if largest_face is not None:
            frames_without_face = 0
            last_successful_tracking_time = current_time

            x, y, w, h = largest_face

            # Calculate face center
            face_center_x = x + w // 2
            face_center_y = y + h // 2

            # Add to position history for smoothing
            face_positions.append((face_center_x, face_center_y))
            if len(face_positions) > max_history:
                face_positions.pop(0)

            # Calculate smoothed face position
            total_weight = 0
            smoothed_x = 0
            smoothed_y = 0

            for i, pos in enumerate(face_positions):
                weight = i + 1
                smoothed_x += pos[0] * weight
                smoothed_y += pos[1] * weight
                total_weight += weight

            smoothed_x /= total_weight
            smoothed_y /= total_weight

            face_center_x = int(smoothed_x)
            face_center_y = int(smoothed_y)

            # Calculate face size (diagonal for better distance estimation)
            face_size = np.sqrt(w ** 2 + h ** 2)

            # NEW: Handle initial face size calibration
            if initial_face_size is None:
                # Collect samples for initial face size
                initial_face_size_samples.append(face_size)

                # Only use recent samples (last 30 frames)
                if len(initial_face_size_samples) > 30:
                    initial_face_size_samples.pop(0)

                # Wait until we have enough samples and face position is stable
                if len(initial_face_size_samples) >= initial_samples_needed:
                    face_size_stabilization_counter += 1

                    # Check if the face position is relatively stable
                    if face_size_stabilization_counter >= 15:  # 15 frames of stability
                        # Calculate average of recent samples as initial face size
                        initial_face_size = sum(initial_face_size_samples) / len(initial_face_size_samples)
                        print(f"Initial face size calibrated: {initial_face_size:.2f}")

                        # Set zoom to 1.5x for this initial face size
                        zoom_factor = 1.5
                        target_zoom = 1.5
                        link_controller.zoom(zoom_factor)
                        last_applied_zoom = zoom_factor

            # Draw rectangle around the face
            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
            cv2.circle(frame, (face_center_x, face_center_y), 5, (0, 255, 0), -1)
            cv2.circle(frame, (center_x, center_y), 5, (0, 0, 255), -1)
            cv2.rectangle(frame,
                          (center_x - movement_threshold, center_y - movement_threshold),
                          (center_x + movement_threshold, center_y + movement_threshold),
                          (255, 255, 0), 1)

            # Calculate offset from center
            offset_x = face_center_x - center_x
            offset_y = center_y - face_center_y  # Inverted for camera control

            # Display offset info
            cv2.putText(frame, f"Offset: ({offset_x:.1f}, {offset_y:.1f})", (10, 90),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            # Calculate PID control values
            p_x = kp * offset_x
            p_y = kp * offset_y
            integral_x = max(-50, min(50, integral_x + ki * offset_x))
            integral_y = max(-50, min(50, integral_y + ki * offset_y))
            d_x = kd * (offset_x - prev_offset_x)
            d_y = kd * (offset_y - prev_offset_y)

            # Calculate control signals
            control_x = p_x + integral_x + d_x
            control_y = p_y + integral_y + d_y

            # Apply non-linear response for small movements
            control_x = np.sign(control_x) * (abs(control_x) ** 0.8)
            control_y = np.sign(control_y) * (abs(control_y) ** 0.8)

            # Only move if offset is significant
            if abs(offset_x) > movement_threshold or abs(offset_y) > movement_threshold:
                # Normalize control signals to range -1 to 1
                max_control = max(1.0, abs(control_x), abs(control_y))
                control_x = control_x / max_control
                control_y = control_y / max_control

                # Apply PTZ movement if enough time has passed since last command
                if current_time - last_ptz_command_time > ptz_command_interval:
                    result = link_controller.micro_pan_tilt(control_x, control_y)
                    last_ptz_command_time = current_time
                    command_sent = True

                consecutive_tracking_frames = 0
            else:
                # Face is centered within threshold
                consecutive_tracking_frames += 1

            # Store current offsets for next iteration
            prev_offset_x = offset_x
            prev_offset_y = offset_y

            # ===== NEW ZOOM LOGIC BASED ON INITIAL FACE SIZE =====
            if initial_face_size is not None and current_time - last_zoom_command_time > zoom_command_interval:
                # Calculate face size ratio compared to initial face size
                size_ratio = face_size / initial_face_size

                # Print debug info
                if debug_mode:
                    print(f"Face size: {face_size:.2f}, Initial: {initial_face_size:.2f}, Ratio: {size_ratio:.2f}")

                # Store previous target for comparison
                prev_target_zoom = target_zoom

                # Clear zoom change status
                zoom_changed = False

                # ZOOM LOGIC:
                # - If face is larger than initial (ratio > 1.0), person is closer, zoom OUT
                # - If face is smaller than initial (ratio < 1.0), person is farther, zoom IN
                if size_ratio > 1.1:  # Face is 10% larger than initial - zoom OUT
                    # Map size_ratio to zoom level: larger ratio = smaller zoom
                    # size_ratio of 1.0 should give zoom of 1.5x
                    # size_ratio of 2.0 or larger should give zoom of 1.0x
                    target_zoom = max(min_zoom, min(max_zoom, 2.5 - size_ratio))
                    zoom_changed = True
                    if debug_mode:
                        print(f"ZOOM ACTION: Face larger than initial, zooming OUT to: {target_zoom:.2f}x")
                elif size_ratio < 0.9:  # Face is 10% smaller than initial - zoom IN
                    # Map size_ratio to zoom level: smaller ratio = larger zoom
                    # size_ratio of 1.0 should give zoom of 1.5x
                    # size_ratio of 0.5 or smaller should give zoom of 3.0x
                    target_zoom = max(min_zoom, min(max_zoom, 3.0 - 1.5 * size_ratio))
                    zoom_changed = True
                    if debug_mode:
                        print(f"ZOOM ACTION: Face smaller than initial, zooming IN to: {target_zoom:.2f}x")
                else:
                    # Face is close to initial size (Â±10%) - maintain 1.5x zoom
                    target_zoom = 1.5
                    if abs(zoom_factor - 1.5) > 0.1:
                        zoom_changed = True
                        if debug_mode:
                            print(f"ZOOM ACTION: Face at initial size, maintaining 1.5x zoom")

                # Apply zoom changes more responsively
                if zoom_changed or abs(target_zoom - zoom_factor) > 0.05:
                    # Move zoom factor towards target (80% of the way each step)
                    zoom_factor = zoom_factor + 0.8 * (target_zoom - zoom_factor)

                    # Round to 2 decimals
                    zoom_factor = round(zoom_factor, 2)

                    # Only send zoom command if it changed enough
                    if abs(zoom_factor - last_applied_zoom) > 0.05:
                        try:
                            print(f"APPLYING ZOOM: {zoom_factor:.2f}x (target: {target_zoom:.2f}x)")
                            result = link_controller.zoom(zoom_factor)

                            if result:
                                print(f"Zoom command successful: {zoom_factor:.2f}x")
                                zoom_command_success_counter += 1
                                zoom_failure_counter = 0
                            else:
                                print(f"Zoom command failed!")
                                zoom_failure_counter += 1

                            last_zoom_command_time = current_time
                            last_applied_zoom = zoom_factor
                            command_sent = True
                        except Exception as e:
                            print(f"Zoom command error: {e}")
                            zoom_failure_counter += 1

            # Display face size info
            cv2.putText(frame, f"Face size: {face_size:.1f}", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

            # Display initial face size if calibrated
            if initial_face_size is not None:
                cv2.putText(frame, f"Initial size: {initial_face_size:.1f}", (10, 150),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        else:
            # No face detected
            frames_without_face += 1

            # Handle cases where no face is detected
            # (rest of the code remains the same as in your original)
            # ...

        # Display zoom factor
        cv2.putText(frame, f"Zoom: {zoom_factor:.2f}x", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        # Display mode and face detection status
        if frames_without_face > 10:
            mode_text = "Searching for Face"
        elif consecutive_tracking_frames > 10:
            mode_text = "Face Centered"
        else:
            mode_text = "Tracking Mode"

        cv2.putText(frame, mode_text, (10, 120),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        # Display frame
        try:
            cv2.imshow("Insta360 Link Face Tracking", frame)
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("Quitting application...")
                break
            elif key == ord('r'):
                print("Resetting camera position...")
                link_controller.reset_position()
                time.sleep(0.5)
                zoom_factor = 1.5
                target_zoom = zoom_factor
                last_applied_zoom = zoom_factor
                link_controller.zoom(zoom_factor)
                # Reset initial face size calibration
                initial_face_size = None
                initial_face_size_samples = []
                face_size_stabilization_counter = 0
                print("Face size calibration reset")
            elif key == ord('c'):
                # Manual calibration of current face size as initial
                if largest_face is not None:
                    initial_face_size = face_size
                    print(f"Manual calibration: Initial face size set to {initial_face_size:.2f}")
                    # Reset zoom to 1.5x for this initial face size
                    zoom_factor = 1.5
                    target_zoom = 1.5
                    link_controller.zoom(zoom_factor)
                    last_applied_zoom = zoom_factor

        except Exception as e:
            print(f"Error in main processing loop: {e}")
            continue

    # Clean up
    print("Shutting down face tracking system...")
    cap.release()
    cv2.destroyAllWindows()

    # Reset camera to default position
    if link_controller.ptz_supported:
        print("Resetting camera to home position...")
        link_controller.reset_position()
        time.sleep(0.5)
        link_controller.zoom(1.0)  # Set zoom to 1x
        print("Camera reset complete")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nProgram interrupted by user. Exiting gracefully...")
    except Exception as e:
        print(f"Unhandled error: {e}")
    finally:
        # Make sure all windows are closed
        cv2.destroyAllWindows()
        print("Cleanup complete. Goodbye!")
